
<!DOCTYPE html>
<html>
<head>
<APM_DO_NOT_TOUCH>

<script type="text/javascript">
(function(){
window.kaye=!!window.kaye;try{(function(){(function(){var Z={decrypt:function(Z){try{return JSON.parse(function(Z){Z=Z.split("l");var S="";for(var I=0;I<Z.length;++I)S+=String.fromCharCode(Z[I]);return S}(Z))}catch(I){}}};return Z={configuration:Z.decrypt("123l34l97l99l116l105l118l101l34l58l34l110l111l34l44l34l100l101l98l117l103l103l105l110l103l34l58l34l110l111l34l44l34l109l111l100l117l108l101l49l34l58l34l101l110l97l98l108l101l100l34l44l34l109l111l100l117l108l101l50l34l58l34l101l110l97l98l108l101l100l34l44l34l109l111l100l117l108l101l51l34l58l34l101l110l97l98l108l101l100l34l44l34l109l111l100l117l108l101l52l34l58l34l101l110l97l98l108l101l100l34l125")}})();
var SZ=45;try{var _Z,jZ,lZ=s(158)?0:1,oZ=s(349)?0:1,Zs=s(707)?0:1,_s=s(95)?1:0,is=s(671)?0:1,ls=s(531)?0:1,os=s(607)?0:1,sZZ=s(322)?0:1;for(var Os=(s(395),0);Os<jZ;++Os)lZ+=s(650)?1:2,oZ+=(s(77),2),Zs+=s(957)?1:2,_s+=s(48)?2:1,is+=s(681)?1:2,ls+=(s(161),2),os+=s(237)?1:2,sZZ+=(s(273),3);_Z=lZ+oZ+Zs+_s+is+ls+os+sZZ;window.ji===_Z&&(window.ji=++_Z)}catch(ZS){window.ji=_Z}var sS=!0;
function _(Z){var S=arguments.length,I=[];for(var L=1;L<S;++L)I.push(arguments[L]-Z);return String.fromCharCode.apply(String,I)}function _S(Z){var S=10;!Z||document[J(S,128,115,125,115,108,115,118,115,126,131,93,126,107,126,111)]&&document[J(S,128,115,125,115,108,115,118,115,126,131,93,126,107,126,111)]!==l(68616527656,S)||(sS=!1);return sS}function J(Z){var S=arguments.length,I=[],L=1;while(L<S)I[L-1]=arguments[L++]-Z;return String.fromCharCode.apply(String,I)}function iS(){}
_S(window[iS[_(SZ,155,142,154,146)]]===iS);_S(typeof ie9rgb4!==l(1242178186154,SZ));_S(RegExp("\x3c")[l(1372160,SZ)](function(){return"\x3c"})&!RegExp(J(SZ,165,96,145))[l(1372160,SZ)](function(){return"'x3'+'d';"}));
var jS=window[J(SZ,142,161,161,142,144,149,114,163,146,155,161)]||RegExp(_(SZ,154,156,143,150,169,142,155,145,159,156,150,145),l(-27,SZ))[_(SZ,161,146,160,161)](window["\x6e\x61vi\x67a\x74\x6f\x72"]["\x75\x73e\x72A\x67\x65\x6et"]),lS=+new Date+(s(637)?380687:6E5),LS,zS,Z_,s_=window[J(SZ,160,146,161,129,150,154,146,156,162,161)],i_=jS?s(139)?22004:3E4:s(112)?4434:6E3;
document[_(SZ,142,145,145,114,163,146,155,161,121,150,160,161,146,155,146,159)]&&document[_(SZ,142,145,145,114,163,146,155,161,121,150,160,161,146,155,146,159)](J(SZ,163,150,160,150,143,150,153,150,161,166,144,149,142,155,148,146),function(Z){var S=37;document[J(S,155,142,152,142,135,142,145,142,153,158,120,153,134,153,138)]&&(document[_(S,155,142,152,142,135,142,145,142,153,158,120,153,134,153,138)]===_(S,141,142,137,137,138,147)&&Z[_(S,142,152,121,151,154,152,153,138,137)]?Z_=!0:document[J(S,155,
142,152,142,135,142,145,142,153,158,120,153,134,153,138)]===J(S,155,142,152,142,135,145,138)&&(LS=+new Date,Z_=!1,I_()))});function I_(){if(!document[J(22,135,139,123,136,143,105,123,130,123,121,138,133,136)])return!0;var Z=+new Date;if(Z>lS&&(s(64)?6E5:566501)>Z-LS)return _S(!1);var S=_S(zS&&!Z_&&LS+i_<Z);LS=Z;zS||(zS=!0,s_(function(){zS=!1},s(908)?0:1));return S}I_();var j_=[s(912)?21485241:17795081,s(244)?2147483647:27611931586,s(932)?1860327411:1558153217];
function l_(Z){var S=7;Z=typeof Z===_(S,122,123,121,112,117,110)?Z:Z[_(S,123,118,90,123,121,112,117,110)](s(908)?35:36);var I=window[Z];if(!I||!I[J(S,123,118,90,123,121,112,117,110)])return;var L=""+I;window[Z]=function(Z,S){zS=!1;return I(Z,S)};window[Z][_(S,123,118,90,123,121,112,117,110)]=function(){return L}}for(var o_=(s(402),0);o_<j_[l(1294399160,SZ)];++o_)l_(j_[o_]);_S(!1!==window[J(SZ,152,142,166,146)]);window.L_=window.L_||{};window.L_.sL="0816ba4918194000ca9e46179e974df16a5b9b9d56a41000dfc0ef55e009d848dbef31d5c0bcd7e74c27b1e344c913fa3ecf21069cfaac5fa6fef0cbd890f12802de78ca8eefa356";
function O_(Z){var S=+new Date,I;!document[_(19,132,136,120,133,140,102,120,127,120,118,135,130,133,84,127,127)]||S>lS&&(s(341)?684103:6E5)>S-LS?I=_S(!1):(I=_S(zS&&!Z_&&LS+i_<S),LS=S,zS||(zS=!0,s_(function(){zS=!1},s(882)?0:1)));return!(arguments[Z]^I)}function s(Z){return 106>Z}function l(Z,S){Z+=S;return Z.toString(36)}(function z_(S){S&&"number"!==typeof S||("number"!==typeof S&&(S=1E3),S=Math.max(S,1),setInterval(function(){z_(S-10)},S))})(!0);})();}catch(x){}finally{ie9rgb4=void(0);};function ie9rgb4(a,b){return a>>b>>0};

})();

</script>
</APM_DO_NOT_TOUCH>

<script type="text/javascript" src="/TSPD/082149a1b4ab2000da5e9abd210e2a94a9f13cf33d6017ad6d2c40248e12a1708b8a1c370520125a?type=9"></script>

  <meta charset="utf-8">
  <meta name="description" content="We propose a framework for relightable portrait animation based on lighting-controllable video diffusion model.">
  
  <meta property="og:title" content="High-Fidelity Relightable Monocular Portrait Animation with Lighting-Controllable Video Diffusion Model"/>
  <meta property="og:description" content="We propose a framework for relightable portrait animation based on a lighting-controllable video diffusion model."/>
  <meta property="og:url" content="https://mingtaoguo.github.io/"/>
  <meta property="og:image" content="static/images/og_tag_header_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>

  <meta name="twitter:title" content="High-Fidelity Relightable Monocular Portrait Animation with Lighting-Controllable Video Diffusion Model">
  <meta name="twitter:description" content="We propose a framework for relightable portrait animation based on lighting-controllable video diffusion model.">
  <meta name="twitter:image" content="static/images/twitter_tag_header_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <meta name="keywords" content="Relighting, Portrait Animation, Video Diffusion Model">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>High-Fidelity Relightable Monocular Portrait Animation with Lighting-Controllable Video Diffusion Model</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">High-Fidelity Relightable Monocular Portrait Animation with Lighting-Controllable Video Diffusion Model</h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="" target="_blank">Mingtao Guo</a><sup>1</sup><sup>†</sup>,</span>
                <span class="author-block">
                  <a href="" target="_blank">Guanyu Xing</a><sup>1</sup><sup>‡</sup>,</span>
                  <span class="author-block">
                    <a href="" target="_blank">Yanli Liu</a><sup>1,2▽</sup>,</span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block"><sup>1</sup>National Key Laboratory of Fundamental Science on Synthetic Vision <br> <sup>2</sup> College of Computer Science <br> Sichuan University, Chengdu, China<br>CVPR 2025</span>
                    <span class="eql-cntrb"><small><br><sup>†</sup> First author  <sup>‡</sup> Second author <sup>▽</sup>Corresponding author</small></span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                      <!-- PDF Link. -->
                      <span class="link-block">
                        <a href="https://arxiv.org/abs/2502.19894" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                  <!-- Code Link. -->
                  <span class="link-block">
                    <a href="https://github.com/MingtaoGuo/Relightable-Portrait-Animation" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
                <!-- ArXiv Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2502.19894" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>




              <!-- TODO Add dataset link -->
              <!-- TODO Add replicate link -->
              <!-- TODO Add colab link -->
              <!-- Colab Link. -->
            <!--   <span class="link-block">
                <a href="" target="_blank"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Colab</span>
                </a>
              </span> -->
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>



<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="static/images/intro.png" alt="Introduction" style="height: 100%;">
      <h2 class="subtitle has-text-centered">
        Qualitative results of our method. The target lighting is applied to the meshes of the driving frames to generate shading hints. Using the shading hints, our relightable portrait animation framework animates and relights the reference frame, e.g., the results within the solid boxes show lighting consistent with the target lighting and poses consistent with the driving frames.    </div>
  </div>
</section>



<section class="section hero is-light">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Relightable portrait animation aims to animate a static reference portrait to match the head movements and expressions of a driving video while adapting to user-specified or reference lighting conditions. Existing portrait animation methods fail to achieve relightable portraits because they do not separate and manipulate intrinsic (identity and appearance) and extrinsic (pose and lighting) features. In this paper, we present a Lighting Controllable Video Diffusion model (LCVD) for high-fidelity, relightable portrait animation. We address this limitation by distinguishing these feature types through dedicated subspaces within the feature space of a pre-trained image-to-video diffusion model. Specifically, we employ the 3D mesh, pose, and lighting-rendered shading hints of the portrait to represent the extrinsic attributes, while the reference represents the intrinsic attributes. In the training phase, we employ a reference adapter to map the reference into the intrinsic feature subspace and a shading adapter to map the shading hints into the extrinsic feature subspace. By merging features from these subspaces, the model achieves nuanced control over lighting, pose, and expression in generated animations. Extensive evaluations show that LCVD outperforms state-of-the-art methods in lighting realism, image quality, and video consistency, setting a new benchmark in relightable portrait animation.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>


<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="static/images/overview.png" alt="Overview" style="height: 100%;">
      <h2 class="subtitle has-text-centered">
Overview of our pipeline for lighting controllable portrait animation. It consists of two main stages: (1) Portrait Attributes Subspace Modeling Stage: We use DECA to encode video frames and extract lighting, pose, and shape parameters, which are rendered as shading hints. After processing the shading hints and reference image through the shading adapter and reference adapter, the two features are randomly selected and fused as guidance to guide the Stable Video Diffusion Model in generating denoised video frames with consistent lighting, pose, identity, and appearance. (2) Relighting and Animation Stage: We render the shading hints using the pose of the portrait from the video, the shape from the reference image, and the spherical harmonics coefficients of the target lighting. After processing the shading hints and reference image through two adapters, we employ multi-condition classifier-free guidance to adjust the magnitude of the extrinsic feature guidance direction, enabling the generation of lighting controllable portrait animations.
  </div>
</section>

<video poster="" id="video2" autoplay controls muted loop height="100%">
  <!-- Your video file here -->
  <source src="static/videos/demo.mov"
  type="video/mp4">
</video>


<!-- Youtube video -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <!-- Paper video. -->
      <h2 class="title is-3">Video Presentation</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          
          <div class="publication-video">
            <!-- Youtube embed code here -->
            <iframe src="https://www.youtube.com/embed/JkaxUblCGz0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End youtube video -->


<!-- Video carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Another Carousel</h2>
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-video1">
          <video poster="" id="video1" autoplay controls muted loop height="100%">
            <!-- Your video file here -->
            <source src="static/videos/carousel1.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video2">
          <video poster="" id="video2" autoplay controls muted loop height="100%">
            <!-- Your video file here -->
            <source src="static/videos/carousel2.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video3">
          <video poster="" id="video3" autoplay controls muted loop height="100%">\
            <!-- Your video file here -->
            <source src="static/videos/carousel3.mp4"
            type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End video carousel -->






<!-- Paper poster -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>

      <iframe  src="static/pdfs/sample.pdf" width="100%" height="550">
          </iframe>
        
      </div>
    </div>
  </section>
<!--End paper poster -->


<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@misc{guo2025highfidelityrelightablemonocularportrait,
      title={High-Fidelity Relightable Monocular Portrait Animation with Lighting-Controllable Video Diffusion Model}, 
      author={Mingtao Guo and Guanyu Xing and Yanli Liu},
      year={2025},
      eprint={2502.19894},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2502.19894}, 
}</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
